{
    "collab_server" : "",
    "contents" : "## Facebook Query Injector #####\n## Mirum Agency ################\n## By Vivek Menon ##############\n## v.1.5.0 #####################\n\n\n# Summary -----------------------------------------------------------------\n\n\n# Todo --------------------------------------------------------------------\n\n# - Run script for all major brands\n# - Create 'participation rate' function\n# - Incorporate Twitter\n\n# Setup -------------------------------------------------------------------\n# Load and install all necessary packages for the script\n\n# Required Packages for dataframes, forecasting, graphical visualization, and development\n# Use 'install.packages()' if unavailable.\n#library(zoo)\n#library(forecast)\nlibrary(ggplot2)\n#library(scales)\nlibrary(devtools)\nlibrary(compare)\nlibrary(xlsx)\n\nrequire(httr)\nrequire(rjson)\nrequire(RCurl)\n\n\n# Pull most up to date Github repositories for relevant packages\n# Not frequently updated; does not need to be run every time.\n#install_github(\"pablobarbera/Rfacebook/Rfacebook\")\n#install_github(\"pablobarbera/instaR/instaR\")\n\n# Required packags for plugging into Facebook API\n#library(twitteR)\n#install.packages('Rfacebook')\nlibrary(Rfacebook)\n\n#library(instaR)\n# https://github.com/pablobarbera/instaR/blob/master/examples.R\n# https://instagram.com/developer/authentication/?hl=en\n\n#setwd(\"~/Desktop/TWE/Monthly Reports/June 2015\")\nsetwd(\"~/\")\ngetwd()\n\n\n# Functions ---------------------------------------------------------------\n\n\n# User Functions\n# Function to convert Facebook date format to R date format\nformat.facebook.date <- function(datestring) {\n  date <- as.POSIXct(datestring, format = \"%Y-%m-%dT%H:%M:%S+0000\", tz = \"GMT\")\n}\n\n# Shift a vector up by an amount\nshift <- function(x, n){\n  c(x[-(seq(n))], rep(NA, n))\n}\n\n# Get gcd from vector\ngcd <- function(x,y) {\n  r <- x%%y;\n  return(ifelse(r, gcd(y, r), y))\n}\n\n\n\n# Inputs ------------------------------------------------------------------\n# Set up script initials; what is the access ftoken, the relevant ids, and other necessary variables\n\n# Define data range for data (2012 is out of bounds for some metrics)\n\n# http://thinktostart.com/analyzing-facebook-with-r/\nfb_oauth <- fbOAuth(app_id=\"955460364539237\", app_secret=\"0a3e6943c90510dc158fc7683e560f7d\",extended_permissions = FALSE)\n\nposts <- 2000\nroof = Sys.Date() #\"2015-12-31\"\nfloor = \"2016-09-27\" #\"2015-05-01\"\nrange = seq(as.Date(floor), as.Date(roof), by=\"days\")\n\n\n## Access ftoken\n# Use token from Facebook Graph API\n# token generated here: https://developers.facebook.com/tools/explorer\n# Lasts two hours, and must be changed depending on page and permissions\n\n\nftokens <- c(\n  #Sledgehammer Wine\n  #\"CAACEdEose0cBAAaqv8JuC9FYYF2JZBzCDyJSrZB5aXhCMHeZAYjdcRkoOyZBHAqNdsSAVnmf63EyT3ZB6pcBZAIcPxcDCQCAXFE1ER62zJDC9tMF6AC5IvTXczksCjh9HocfSBYA1qjER8wsoFvPUF1B9f4mMhNrnAPWRZADbliPBRDTh0D2qF72LAPwZCsfw3UZD\"\n  #Chateau Saint Jean\n  #\"EAACEdEose0cBAOwwfrVCmYxjRlHVlMDJAjtEJkfMZBkWVsQbDGv0eXi50MZCc4F2i33vbhmJ6823oIzAbhezsZAkqchpPpYaiB8XzcfZBKS2jSXE22EY1e855OvkfgFyjKPiOPOjOZAQIbDiJg1tHCMMLVjUlwPcoKGBEexWbGQZDZD\"\n  #19 Crimes\n  #,\"EAACEdEose0cBANCXTZAFtviL9VEUq4DhkEwMyzqdmWgZBh68EReZAIEOVBYlTSiS52swRACvjhybfPQGFqEOmJp0OjTSPQ9ZC01R6nxViJ5xDHXPlDCwnnXOBObHYwZAXhQzy52kL3FZA3WcHNrGNIqfJZC9MZCJPkkfXHpVsx3PHQZDZD\"\n  #Beringer Vneyards\n  #,\"EAACEdEose0cBAAfj1KkrLbPzVw0v5gul87LeUeoXUHnN6rlxrVRklAgg214vFGLkQTKeLHEUWDGg9ZBVeTDRQdOietA25FLcAaQCGiKvmLFv3ZAYnMpLg9YKnpNpazKjXKwWpkXZBdjuKB7Ql6JKu4Q8pNOZCk97LWSwW4U8vgZDZD\"\n  #100% Canadian Milk\n  #\"EAANkZCHOgFWUBAJZCvRlC7OapZBTJNXWibKAXkVi09U4IgYweulZANtxZB3GTuNBOC7HKkXCu2nKSJwyAJVimuk4VdHWUyVQtufu8io4uNJILPctxkOs51myVMErxwdXe6yFHWrzABRadSI9QpNGmvWkxpO8fjrdmVpqe3XgOUQZDZD\"\n  #Lait 100% Canadien\n  #,\"EAANkZCHOgFWUBAOfjVgEIn6mY1OHt6ZCwaZA8RGhMlDX9l2UUZCAOLylBVZBWpaXyFyyjRqo5eYnZBTYTgrRbIkZA95ZAiuJZBZBwqtjs60zNMNpj7Dn9rqnR4BI2czMR7lB84wIw0ikJSwXxZAcBpFBG0NFUP8q2spL7ZBitHw7Q9EY8QZDZD\"\n  #Recharge with Milk\n  #,\"CAACEdEose0cBAJ9NPmffbszUQ1HYObOGqdht5XWBoU7zABLhgZB6L53eyqVrt0CPxkZAXQpI0fGW7FHucQ0LgGtmRRlWP6eAQgZBSa6oaRibk9qZAp0xVGZCr4B6AdysmfVlbZCFjoZBYZCJ3sxN1yMdL5jz6yCWOZAAbAv00nXq5wURrgCUe3dXZAZBF2COnBm9YxXk5vFoWWJkQZDZD\"\n  #BaronSamedi\n  \"EAACEdEose0cBAGLivuq5Aurqa4K6DZBkBRHHIcZCHLD3u0sdhMvUE3kEmAos9Ql3M1x51t7aAOKx9DQbhbKRnRSwbaP23rdC0RRkCcv72ZBCKhG6CbxqDTMxbb9vAfEpMwmjm6lcs0xAkYnZClxUBUDxCVjZBodjdn9BqVM5xfAZDZD\"\n  )\n\ntotalpagedata <- data.frame()\ntotalpostdata <- data.frame()\n\nfor (brand in 1:length(ftokens)) {\n  ftoken <- ftokens[brand]\n\n  ## User Id\n  # Set up the user profile that will be accessing the data (must have all appropriate permissions/be Page Admin)\n  userid = \"10153046308598756\"\n\n  # Access public personal data; basically a ftoken test\n  me <- getUsers(\"me\", token=ftoken)\n  print(me$name)\n\n  ## Page Id\n  # Define which page will be used for the data collection. Change id's as necessary.\n  # Can use Pagename or ID; ID is generally preferable. Can be found through Facebook Business Manager: https://business.facebook.com/\n\n  pageid = me$id\n\n\n  # Acquisition -------------------------------------------------------------\n  # Grab/Load all Facebook Page & Post data until today for the Page defined.\n\n  page <- getPage(pageid, ftoken, n = posts)\n  page.store <- page\n\n  # Create new vectors in dataset with datetime, month, and day formattiong\n\n  if ((is.null(page$datetime[1]) & is.null(page$month[1]) & is.null(page$day[1])) == TRUE) {\n    page$datetime <- format.facebook.date(page$created_time)\n    page$month <- format(page$datetime, \"%Y-%m\")\n    page$day <- format(page$datetime, \"%Y-%m-%d\")\n\n    page$datetime <- as.Date(page$datetime)\n    #page$month <- as.Date(page$month)\n    page$day <- as.Date(page$day)\n  } else {\n    print(\"Date fields already exist.\")\n  }\n\n\n  # Processing --------------------------------------------------------------\n  # Process data to clean dataset and augment it with more data than default fields.\n  # Check full package documentation for reference: http://cran.r-project.org/web/packages/Rfacebook/Rfacebook.pdf\n\n\n## Cleaning =================================\n\n# Page and Post Datasets\n# Split dataset into two for pages and post data\n# Create initial null sets\npagedata <- 0\npostdata <- 0\n\n## Appending =================================\n\n### Page Metrics #############################\n# Loop through all dates for the specified metric(s), and append the page dataset with metric values\n# Some are automated, others are manual; after the script. Re-run from pull loop if there is an error; should auto-try until values are found.\n\n# Page Metrics to automatically pull\n# \"page_fans_online\" ,\"page_fans_gender_age\", \"page_positive_feedback_by_type\"\nmetrics = c(\"page_impressions\",\"page_impressions_unique\", \"page_impressions_paid_unique\", \"page_engaged_users\", \"page_fans\",\"page_consumptions\") #c(\nnames(metrics) = c(\"Impressions\",\"Total Reach\",  \"Paid Reach\", \"Engaged Users\", \"Fans\", \"Page Consumptions\")\n\npagemetrics <- metrics\n\n\n# Prep dataset by breaking into weeks\npagedata <- 0\npagedata <- cbind(page[1:length(range), c(\"from_id\",\"from_name\")],rev(range))\n\n\ncolnames(pagedata) = c(\"pageid\", \"page\", \"date\")\n\npagedata$page = page$from_name[1]\npagedata$pageid = page$from_id[1]\n\ndivisor = 5\nremainder = length(range)%%divisor;\npagedata <- pagedata[1:(nrow(pagedata)-remainder),]\n\nweeks <- (nrow(pagedata)/5)-2\n\n# Start Data Acquisition Loop\nfor (metric in 1:length(metrics)) {\n\n  print(paste('Finding', names(metrics)[metric],'for',pagedata$page[1]))\n\n  if ((metrics)[metric] == 'page_fans' | (metrics)[metric] == 'page_fans_gender_age') {\n    period = 'lifetime'\n  } else if ((metrics)[metric] == 'page_positive_feedback_by_type'| (metrics)[metric] == 'page_positive_feedback_by_type' ) {\n    period = 'day'\n\n    tempfloor = \"2014-02-01\"\n    temprange = seq(as.Date(tempfloor), as.Date(roof), by=\"days\")\n\n    if (floor < tempfloor) {\n\n    tempremainder = length(range[(length(range)-length(temprange)+1):length(range)])%%5\n    tempweeks  = (length(temprange) - tempremainder)/5 - 2\n    weeks = tempweeks\n\n    } else {}\n    } else {\n    period = 'day'\n    weeks <- (nrow(pagedata)/5)-2\n  }\n\n  hold <- matrix(0, nrow=0, ncol=7)\n\n  for (week in 0:weeks) {\n\n    end <- pagedata$date[(week*5)+1]\n    start <- pagedata$date[((week+1)*5)+1]\n\n    print(paste('Finding', names(metrics)[metric],'for',pagedata$page[1],'from',start,'to',end))\n\n    pull <- NULL\n    attempt <- 1\n\n    while(is.null(pull) && attempt <= 10) {\n      attempt <- attempt + 1\n      try(\n        pull <- getInsights(object_id=pageid, token=ftoken, metric=metrics[metric], period=period, parms=paste0('&since=',start,'&until=',end))\n      )\n\n      if (is.null(pull)) {\n        print(\"Empty Pull. Re-attempting.\")\n        print(paste(\"Attempt\", attempt))\n      } else {\n        pull$datetime <- format.facebook.date(pull$end_time)\n        pull$day <- format(pull$datetime, \"%Y-%m-%d\")\n\n        pull$datetime <- as.Date(pull$datetime)\n        #page$month <- as.Date(page$month)\n        pull$day <- as.Date(pull$day)\n\n        if ((seq(from=start, to=(end-1), by = \"days\")[1] == pull$day[1]) & (seq(from=start, to=end, by = \"days\")[5] == pull$day[length(pull$day)]) == TRUE) {\n          print(\"Found Facebook data matching date range. Storing values.\")\n        } else {\n          print(\"Did not find Facebook data matching dataset dates. Re-querying.\")\n          print(paste(\"Attempt\", attempt))\n          pull <- NULL}\n\n        if (attempt > 100) {\n          print('Too many attempts. Skipping.')\n          pull <- NULL\n          break\n        } else {}\n      }\n\n      pulllength <- ncol(pull)\n\n      rpull = pull[rev(rownames(pull)),]\n\n      hold <- rbind(hold,rpull)\n      rawhold <- hold\n    }\n  }\n\n\n\n  rhold = hold[rev(rownames(hold)),]\n  rhold$value = shift(rhold$value, 1)\n  hold = rhold[rev(rownames(rhold)),]\n  hold$value[1] = rawhold$value[1]\n\nhours <- seq(0,23)\nnames(hours) <- paste(\"Hour\", hours)\n\nsubtypes <- c('link','comment', 'like')\nnames(subtypes) <- c('Shares','Comments', 'Likes')\n\ndemographics <- c(\"F.65+\",\"F.55-64\", \"F.45-54\",\"F.35-44\", \"F.25-34\", \"F.18-24\", \"M.65+\", \"M.55-64\", \"M.45-54\", \"M.35-44\",\"M.25-34\", \"M.18-24\")\nnames(demographics)  <- c(\"Females 65+\", \"Females 55-64\", \"Females 45-54\", \"Females 35-44\", \"Females 25-34\", \"Females 18-24\",  \"Males 65+\", \"Males 55-64\", \"Males 45-54\", \"Males 35-44\", \"Males 25-34\", \"Males 18-24\")\n\n# Posting demographics at the end of the loop as metrics[metric]; fix the tail end of the loop.\n\n  if ((metrics)[metric] == 'page_positive_feedback_by_type') {\n\n    for (type in 1:length(subtypes)) {\n      typehold <- NA\n      typehold <- hold[hold$variable == subtypes[type],]\n\n      pagedata <- cbind(NA,pagedata)\n      pagedata[2:(length(typehold$day)+1),1] <- (typehold$value)\n      colnames(pagedata)[1] = paste0(tolower(names(subtypes[type])))\n\n      metrics <- c(metrics,subtypes[type])\n    }\n\n\n  } else if ((metrics)[metric] == 'page_fans_gender_age') {\n\n    for (demographic in 1:length(demographics)) {\n\n      print(names(demographics[demographic]))\n\n      typehold <- NA\n      typehold <- hold[hold$variable == demographics[demographic],]\n      typehold[typehold$value <= 10,] <- NA\n\n      pagedata <- cbind(NA,pagedata)\n      pagedata[2:(length(typehold$day)+1),1] <- (typehold$value)\n      colnames(pagedata)[1] = paste0(tolower(demographics[demographic]))\n\n      metrics <- c(metrics,demographics[demographic])\n    }\n\n  } else if ((metrics)[metric] == 'page_fans_online') {\n\n    for (hour in 1:length(hours)) {\n\n      typehold <- NA\n      typehold <- hold[hold$variable == hours[hour],]\n\n      pagedata <- cbind(NA,pagedata)\n      pagedata[2:(length(typehold$day)+1),1] <- (typehold$value)\n      colnames(pagedata)[1] = paste(\"hour\",hours[hour])\n\n      metrics <- c(metrics,hours[hour])\n    }\n  } else {\n    pagedata <- cbind(NA,pagedata)\n    pagedata[2:(length(hold$day)+1),1] <- (hold$value)\n    colnames(pagedata)[1] = paste0(tolower(names(metrics[metric])))\n\n  }\n\n  cat(\"\\n\\n\")\n  print(head(pagedata))\n  cat(\"\\n\")\n\n  if (length(metrics) == (length(pagemetrics)  + length(demographics) + length(hours))) {\n    break\n  } else {\n  }\n\n}\n\npagedata.tempstore <- pagedata\n\n#Page Metrics to remove because they have subtypes\nmetrics <- metrics[-c(which(metrics == \"page_positive_feedback_by_type\"),which(metrics == \"page_fans_gender_age\"),which(metrics == \"page_fans_online\"))]\n\n# Page Metrics to manually create\nmetrics <- c(metrics,\"organic reach\")\nnames(metrics)[length(metrics)] <- c(\"Organic Reach\")\n\npagedata <- cbind((as.numeric(pagedata$`total reach`) - as.numeric(pagedata$`paid reach`)),pagedata)\ncolnames(pagedata)[1] = \"organic reach\"\n\n# Final dataset formatting\npagedatastore <- pagedata\n#pagedata <- pagedatastore\npagedata2 <- pagedata\n\n# reorder and null NA's for excel\npagedata2 <- pagedata2[,c((ncol(pagedata)-2), (ncol(pagedata)-1),(ncol(pagedata)),(1:(ncol(pagedata)-3)))]\npagedata2 <- pagedata2[2:nrow(pagedata2),]\n#pagedata2[is.na(pagedata2)] <- \"\"\n#pagedata2[pagedata2 == 0] <- \"\"\n\n# store final dataset\npagedata <- pagedata2\n\n### Post Metrics #############################\n# Loop through all posts for the specified metric(s), and append the post dataset with metric values\n# Most are automated, and will continue to retry through errors until a value is found.\n# Manual modifications are run after initial data acquisition.\n\npostmetrics = c(\"post_impressions_unique\",\"post_impressions_paid_unique\",\"post_video_views_organic\",\"post_video_views_paid\",\"post_video_complete_views_organic\",\"post_video_complete_views_paid\",\"post_engaged_users\",\"post_consumptions_by_type\")\nnames(postmetrics) = c(\"Total Reach\", \"Paid Reach\",\"Organic Video Views\", \"Paid Video Views\", \"Organic Complete Video Views\", \"Paid Complete Video Views\",\"Engaged Users\", \"Post Consumptions\")\n\n# Populate sets with values from pull\n\nif ((is.null(page$datetime[1]) & is.null(page$month[1]) & is.null(page$day[1])) == TRUE) {\n  page$datetime <- format.facebook.date(page$created_time)\n  page$month <- format(page$datetime, \"%Y-%m\")\n  page$day <- format(page$datetime, \"%Y-%m-%d\")\n\n  page$datetime <- as.Date(page$datetime)\n  #page$month <- as.Date(page$month)\n  page$day <- as.Date(page$day)\n} else {\n  print(\"Date fields already exist for Post Data.\")\n}\n\npostdata <- 0\npostdata <- page[page$day > floor,]\npostdata <- postdata[postdata$day < roof,]\n\n#write.xlsx(postdata, paste0(paste(me$name,floor,\"to\",roof,sep=\" \"),\".xlsx\"), row.names=FALSE)\n\n\n# Name column for usability\ncolnames(postdata) = c(\"pageid\", \"page\", \"message\", \"created\", \"type\", \"link\", \"postid\", \"likes\", \"comments\", \"shares\", \"datetime\", \"month\",\"day\")\n\nrows <- nrow(postdata)\nlpostmetrics <- postmetrics\n\ntestlength <- 2\n#length(postmetrics) instead of testlength; swapped out for hotfixes\n\n\nfor (pmetric in 1:length(postmetrics)) {\n  print(paste('Finding', names(postmetrics)[pmetric],'for',postdata$page[1]))\n\n  if ((substr((postmetrics)[pmetric], 1, 17) == ('post_consumptions'))) {\n    phold <- data.frame(0,0,0,0,0,0,0, stringsAsFactors=FALSE)\n    names(phold) <- c(\"id\",\"name\",\"period\",\"title\",\"description\",\"value\",\"variable\")\n  } else {\n    phold <- data.frame(0,0,0,0,0,0, stringsAsFactors=FALSE)\n    names(phold) <- c(\"id\",\"name\",\"period\",\"title\",\"description\",\"value\")\n  }\n\n\n  for (post in 1:nrow(postdata)) {\n\n    period <- \"lifetime\"\n\n\n    print(paste('Finding', names(postmetrics)[pmetric],'for',postdata$page[1], postdata$type[post],'post:',paste0(substr(postdata$message[post], 1, 80),\"...\")))\n\n      if ((substr((postmetrics)[pmetric], 1, 10) == ('post_video')) & (postdata$type[post] != 'video')) {\n      print('Not a Facebook Video.')\n      phold <- rbind(phold, NA)\n      next()\n      } else if ((substr((postmetrics)[pmetric], 1, 10) == ('post_video')) & (postdata$type[post] == 'video') & (substr(postdata$link[post], 12, 18) != 'youtube') & (substr(postdata$link[post], 8, 15) != 'youtu.be')) {\n      } else {\n      }\n\n\n    postpull <- NULL\n    attempt <- 1\n\n    while( is.null(postpull) && attempt <= 100) {\n      attempt <- attempt + 1\n      try(\n        postpull <- getInsights(object_id=postdata$postid[post], token=ftoken, metric=postmetrics[pmetric], period=period)\n        ,silent=TRUE\n      )\n      if (attempt > 10) {\n        print('Too many attempts. Skipping.')\n        postpull <- NULL\n        break\n      } else {\n      }\n    }\n\n    colnames(phold) <- names(postpull)\n    phold <- rbind(phold, postpull)\n  }\n  pholdstore <- phold\n\n  psubtypes <- c('other clicks','photo view', 'link clicks', 'video play')\n  names(psubtypes) <- c('Other Clicks','Photo Views', 'Link Clicks', 'Video Plays')\n\n  phold <- phold[-1,]\n\n  if ((postmetrics)[pmetric] == 'post_consumptions_by_type') {\n\n    postmetrics <- postmetrics[-pmetric]\n    pmetric <- pmetric + 1\n\n    for (ptype in (1:length(psubtypes))) {\n      ptyphehold <- NA\n      ptypehold <- phold[phold$variable == psubtypes[ptype],]\n\n      postdata <- cbind(NA,postdata)\n      postdata[match(substr(ptypehold$id, 1, 22), substr(postdata$postid, 1, 22)),1] <- ptypehold$value\n\n      colnames(postdata)[1] = paste0(tolower(names(psubtypes[ptype])))\n      postmetrics <- c(postmetrics,psubtypes[ptype])\n    }\n\n\n  } else {\n    postdata <- cbind(NA,postdata)\n    postdata[1:length(phold$value),1] <- phold$value\n    colnames(postdata)[1] = paste0(tolower(names(postmetrics[pmetric])))\n  }\n\n\n  cat(\"\\n\\n\")\n  print(head(postdata))\n  cat(\"\\n\")\n}\n\npostdatastore <- postdata\n\n\n\n# Post Metrics to manually create\npostmetrics <- c(postmetrics,\"organic reach\")\nnames(postmetrics)[length(postmetrics)] <- c(\"Organic Reach\")\n\npostdata <- cbind((as.numeric(postdata$`total reach`) - as.numeric(postdata$`paid reach`)),postdata)\ncolnames(postdata)[1] = \"organic reach\"\n\n# Final dataset formatting\n#postdatastore <- postdata\n#postdata <- postdatastore\n\n#head(postdatastore[,c((ncol(postdata)-12),(ncol(postdata)-11),(ncol(postdata)-9),(ncol(postdata)-2), (ncol(postdata)-1),ncol(postdata),(ncol(postdata)-6),(ncol(postdata)-7),(ncol(postdata)-8),(ncol(postdata)-10),(ncol(postdata)-5),(ncol(postdata)-4),(ncol(postdata)-3),(1:(ncol(postdata)-13)))])\n\n# reorder and null NA's for Excel\npostdata2 <- postdata\npostdata2 <- postdata2[,c((ncol(postdata)-12),(ncol(postdata)-11),(ncol(postdata)-9),(ncol(postdata)-2), (ncol(postdata)-1),ncol(postdata),(ncol(postdata)-6),(ncol(postdata)-7),(ncol(postdata)-8),(ncol(postdata)-10),(ncol(postdata)-5),(ncol(postdata)-4),(ncol(postdata)-3),(1:(ncol(postdata)-13)))]\npostdata2[is.na(postdata2)] <- \"\"\npostdata2[postdata2 == 0] <- \"\"\n\n# store final dataset\npostdata <- as.data.frame(postdata2)\n\n# Outputs -----------------------------------------------------------------\n\npagedata[,-c(1:3)] <- sapply(pagedata[,-c(1:3)], as.numeric)\npostdata[,-c(1:10)] <- sapply(postdata[,-c(1:10)], as.numeric)\n\ndatafolder <- \"Data\"\n\ndir.create(file.path(getwd(), datafolder), showWarnings = FALSE)\n\n# Rename columns for Excel readability\n#names(pagedata) = c(\"Page ID\", \"Page Name\", \"Date\", rev(names(metrics)))\n# output Page dataset as final csv\n#write.csv(pagedata, paste0(paste(page$from_name[1],\"Page Data\",Sys.Date(), sep=\" \"),\".csv\"),row.names=FALSE, fileEncoding='iso-8859-1')\nwrite.xlsx(pagedata, paste0(getwd(),\"/\",datafolder,\"/\",paste(page$from_name[1],\"Page Data\",Sys.Date(), sep=\" \"),\".xlsx\"), row.names=FALSE, showNA=FALSE)\n?wri\n# Rename columns for Excel readability\n#names(postdata) = c(\"Page ID\", \"Page Name\", \"Created\",  \"Datetime\", \"Month\", \"Day\", \"Post ID\", \"Link\", \"Type\", \"Message\", \"Likes\", \"Comments\", \"Shares\", rev(names(postmetrics)))\n# output Post dataset as final Excel\n#write.csv(postdata, paste0(paste(page$from_name[1],\"Post Data\",Sys.Date(), sep=\" \"),\".csv\"),row.names=FALSE)\nwrite.xlsx(postdata, paste0(getwd(),\"/\",datafolder,\"/\",paste(page$from_name[1],\"Post Data\",Sys.Date(), sep=\" \"),\".xlsx\"), row.names=FALSE, showNA=FALSE)\n\n# Raw Data\n# output dataset as raw csv\n#write.csv(page, paste0(paste(me$name,\"Raw Data\",Sys.Date(), sep=\" \"),\".csv\"),row.names=FALSE)\n\ntotalpagedata <- rbind(totalpagedata, pagedata)\ntotalpostdata <- rbind(totalpostdata, postdata)\n\n}\n\nwrite.xlsx(totalpagedata, paste0(getwd(),\"/\",datafolder,\"/\",paste(\"Baron\",\"Page Data\",Sys.Date(), sep=\" \"),\".xlsx\"), row.names=FALSE, showNA=FALSE)\n# Rename columns for Excel readability\n#names(postdata) = c(\"Page ID\", \"Page Name\", \"Created\",  \"Datetime\", \"Month\", \"Day\", \"Post ID\", \"Link\", \"Type\", \"Message\", \"Likes\", \"Comments\", \"Shares\", rev(names(postmetrics)))\n# output Post dataset as final Excel\n#write.csv(postdata, paste0(paste(page$from_name[1],\"Post Data\",Sys.Date(), sep=\" \"),\".csv\"),row.names=FALSE)\nwrite.xlsx(totalpostdata, paste0(getwd(),\"/\",datafolder,\"/\",paste(\"Baron\",\"Post Data\",Sys.Date(), sep=\" \"),\".xlsx\"), row.names=FALSE, showNA=FALSE)\n\n# Images\n#imagefolder <- paste0(\"Images\",\"/\",paste(page$from_name[1],sep=\" \"))#,floor,\"to\", roof, sep=\" \"))\n\n#for (picture in (1:nrow(postdata))) {\n#  dir.create(file.path(getwd(), imagefolder), showWarnings = FALSE)\n#\n#  imageURL <- fromJSON(getURL(paste('https://graph.facebook.com/v2.4/',postdata$`Post ID`[picture],'?fields=full_picture&access_token=',ftoken,sep=\"\")))$full_picture\n#  filename <- paste0(getwd(), \"/\", imagefolder, \"/\", postdata$`Post ID`[picture], \".png\")\n#\n#  try(GET(imageURL, write_disk(filename, overwrite=TRUE)))\n\n\n# Edit the core program and change feedback loop.\n\n#\n#}\n",
    "created" : 1453473938337.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "275|0|283|0|\n",
    "hash" : "2419065334",
    "id" : "3A795224",
    "lastKnownWriteTime" : 1479138407,
    "last_content_update" : 0,
    "path" : "~/Desktop/FacebookScraper.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}