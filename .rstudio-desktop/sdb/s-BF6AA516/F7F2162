{
    "collab_server" : "",
    "contents" : "## Facebook Query ##############\n## By Vivek Menon ##############\n## v2.0.0 #####################\n\n\n# Summary -----------------------------------------------------------------\n# Query Facebook data (Page, Post, & Ad) using Facebook Acess Tokens.\n\n\n# Setup -------------------------------------------------------------------\n# Load and install all necessary packages for the script\n\n# Required Packages for dataframes, forecasting, graphical visualization, and development\n# Use 'install.packages()' if unavailable\n\n#library(zoo)\n#library(forecast)\nlibrary(devtools)\nlibrary(ggplot2)\n#library(scales)\nlibrary(devtools)\nlibrary(compare)\nlibrary(xlsx)\nlibrary(httr)\nlibrary(rjson)\nlibrary(RCurl)\nlibrary(roxygen2)\n\n# Pull most up to date Github repositories for relevant packages\n# Not frequently updated; does not need to be run every time\n#install_github(\"pablobarbera/Rfacebook/Rfacebook\")\n#install_github(\"pablobarbera/instaR/instaR\")\nlibrary(Rfacebook)\n\n\n# User Functions ----------------------------------------------------------\n# Some built/discovered functions that help with data manipulation\n\n# Convert Facebook date format to R date format\nUnixDate <- function(datestring) {\n  return(as.POSIXct(datestring, format = \"%Y-%m-%dT%H:%M:%S+0000\", tz = \"GMT\"))\n}\n\n# Convert retrieved dates to readable dates and append the dataset\nFormatDate <- function (dataset) {\n  #return(names(dataset))\n  if ('created_time' %in% names(dataset)) {\n    if (c('day') %in% names(dataset) == FALSE) {\n      dataset[, 'datetime'] = UnixDate(dataset$created_time)\n      dataset[, 'day'] = format(dataset$datetime, \"%Y-%m-%d\")\n      dataset[, 'month'] = format(dataset$datetime, \"%Y-%m\")\n    } else {\n      print('Date fields already exist.')\n      continue\n    }\n  } else {\n    print('created_time field does not exist')\n  }\n}\n    if (is.null(dataset$datetime[1]) == TRUE) {\n    df$datetime <- UnixDate(page$created_time)\n\n    dataset <- df\n  } else {\n    print(\"Date fields already exist.\")\n  }\n}\n\n\n\n} & is.null(df$month[1]) & is.null(df$day[1])) == TRUE) {\n    df$month <- format( df$datetime, \"%Y-%m\")\n    df$day <- format( df$datetime, \"%Y-%m-%d\")\n\n# Shift a vector up by an amount\nshift <- function(x, n){\n  c(x[-(seq(n))], rep(NA, n))\n}\n\n# Get gcd from vector\ngcd <- function(x,y) {\n  r <- x%%y;\n  return(ifelse(r, gcd(y, r), y))\n}\n\n#\n\n\n# Inputs ------------------------------------------------------------------\n# Set up script initials; what is the access ftoken, the relevant ids, and other necessary variables\n\n\n# Facebook App paramaters (Available at developer.facebook.com)\n# Must be set up with localhost:1400 acess for verification\napp_id = \"955460364539237\"\napp_name = \"r_access\"\napp_secret = \"0a3e6943c90510dc158fc7683e560f7d\"\nscope = \"ads_management,manage_pages,publish_actions\"\n\n\n\n# Set Desktop as working directory\nsetwd(\"~/\")\ngetwd()\n\n# Authorize with Facebook\n#Using 'rFacebook' from Github\nfboauth <- fbOAuth(app_id = app_id, app_secret ,extended_permissions = scope)\n#callAPI(\"https://graph.facebook.com/v2.4/act_693722000711682/adgroups?fields=name&limit=1000\", fboauth)\n\n\n# Define data range for data (2012 is out of bounds for some metrics)\n\n# Facebook Functions ------------------------------------------------------\n# A higher level wrap up of some Pablo's functions, in order to allow easy deployment\n\n#FacebookAuth = function (app_id, app_secret, scope) {\n\n  #fbOAuth(app_id = app_id, app_secret,extended_permissions = scope)\n#}\n\n# Create looper for Ftokens\n\n\nftokens <- c(\n  #Sledgehammer Wine\n  #\"EAACEdEose0cBAEyF7hkNB6lPbRHGjf0vKqW9ZB8sZBSy3LUGTUelMy8ZBE4rTo1HWZAc6IbZBUDkE6p7lhQ7FeCtxb1P0nUvy9x3ltkZCmcP1CyxSaSDZAwlPsUwZBysAtvvTCuqjDxmqZCYv5X4t2GKsZAVENiMZAkcur64cU7qu71xgZDZD\"\n  #Chateau Saint Jean\n  #,\"EAACEdEose0cBAB6y1eZButlUqpuUt1IUau7lDlZChQxE4MiXWMZCuWkCLsI9yZCajIEnIQVxZCQrmR2XMJdsaufMRhh5QOkVrzwcMZAZCC4FctcBfZByjZCVsctpvMmPKJLGRWyyToWvMqxM4CBLi3rELZCipHbfI8QgCj04Py8ZCgVRAZDZD\"\n  #19 Crimes\n  #,\"EAACEdEose0cBAHIQiWkKO8TdkDpxnojS1lDoZATgRap3L8Sz3D0B7WUYilnpj1NvnltXTbOE12QSnEDvjO2KmUZAvMRy3dVrZCBHP9ZCNiGjbXRK5QCkwsA7Vn5cD9oW9BSOGHb92N3o0j9t3ZAlptZA9kGjTv3qymVOvlsg5b7QZDZD\"\n  #Beringer Vneyards\n  #,\"EAACEdEose0cBAP5NwqMtlIxi8HWYe4G6CP1hpHRatyK5AN1X6CDIVu1nDOfSZAI8ovTF4ibkwpkH1NMxEPwBdOgemK6nnbl8rsNF1mCoCYho4wMLrWdlYD5zJuJEOcMOJWJsECwKfFycVIdpymSoFZAq91ZBDZBUkz2DU3OZARgZDZD\"\n  #100% Canadian Milk\n  #\"EAANkZCHOgFWUBAEmrJ2GBsINYbyetoAGRrBKU2tZCPWOWlodmBS9gknNFH3zBfvXCtTYnRsgRVzZAr5LOdAnZBVLj8zX3Xuv7oVxbmmcNfiNZCTTpQfbdWmHb2W1yZAtakecO9yeCPjPljAxRZAagdxsH82IA9wdk56xdi2KUZB28AZDZD\"\n  #Lait 100% Canadien\n  #,\"EAANkZCHOgFWUBAOoOsD3RKLwZC1VGegdIoBB9etcfOL6ToGEpNtzxQkrdsen3VKzwZAQ5ozZCsmDU3KYZBeA4Fg1uJPS6PjW5UlWH2LweqsQq2C4j057ARFvAvSJ5pRKkvsy9nxgaBX68y9vXwTysxTTSIGcYczADujwgOjr1kQZDZD\"\n  #Recharge with Milk\n  #\"CAACEdEose0cBAOJTY92DXO6QhwzjMdZCoKRL3yzT368z5HRGfTfWUGUF6iQXpmZAXTaP7BmZBIyXQjGvM24ZAJt1eF1Q9wuwwMoCTgV6Gx1WvUvxY8atshn1c4KVifHSLuBZBIaUIdYTGcWqKgK9TDIG6pPZB8ZBAt9W8ctmrGBRBGQTVoZC5nJfMwnTYtn8CdlE6PCfZCfNdlwZDZD\"\n  #Misc\n  #\"CAACEdEose0cBABMyV5dpn0JkPG16eTh0YOSmEsxtStECA4YR0ZCd6pR2ZBsjqMxxhQ4RVyYNfHtHU2ZAPsmJ2w1UpKNGeWz85RsQio0PXQNqjaafJxw2Hu8VJuj1UOtj8hZBTBMrXIZBKreB43QoZANuVuypgXbsCuEEZCI0pBJeg9KuEkrCyYMOrV1eYDYgP3ZA1BeDoJGUswZDZD\"\n  #Baron\n  #\"EAACEdEose0cBAGLivuq5Aurqa4K6DZBkBRHHIcZCHLD3u0sdhMvUE3kEmAos9Ql3M1x51t7aAOKx9DQbhbKRnRSwbaP23rdC0RRkCcv72ZBCKhG6CbxqDTMxbb9vAfEpMwmjm6lcs0xAkYnZClxUBUDxCVjZBodjdn9BqVM5xfAZDZD\"\n  #Nissan\n  \"EAACEdEose0cBABXvvmZAnd5lP7iBBfyENOdt8E1DxBECZCFIiIWZBOAn7HxjbA0EzwRUDgi5RRDwBtnwNPTbqEIGeW4ykmV0PEZCyigZCQShZANVtkJbJrA4N1KtAW1B7frwvV8NhAIQxqwYDyL9GszHarCjIZCB7P9u49S9WJdOalFnBJYWacW2T4taUURDZAIZD\"\n)\n\n\n  # Access public personal data; basically a ftoken test\n  me <- getUsers(\"me\", token=ftoken[1])\n  print(me$name)\n\n  ## Page Id\n  # Define which page will be used for the data collection. Change id's as necessary.\n  # Can use Pagename or ID; ID is generally preferable. Can be found through Facebook Business Manager: https://business.facebook.com/\n\n  pageid = me$id\n}\n\nposts = '5000'\nstart.date = Sys.Date() - 252\nend.date = Sys.Date()\n\n# Page Metrics to automatically pull\ndailymetrics = c(\"page_impressions_unique\",\"page_impressions\", \"page_impressions_paid_unique\", \"page_engaged_users\", \"page_fans\",\"page_consumptions\")\n\nlifetimemetrics = c('')\n\n#c(\n#names(metrics) = c(\"Page Fans Online\",\"Impressions\",\"Total Reach\",  \"Paid Reach\", \"Engaged Users\", \"Fans\", \"Page Consumptions\", \"Fan Demographics\", \"Page Feedback\")\n\nFacebookPageData = function(ftoken, posts, start.date, end.date, metrics) {\n  unix.start.date = UnixDate(start.date)\n  unix.end.date = UnixDate(end.date)\n\n  # Setup date range\n  date.range = seq(as.Date(start.date), as.Date(end.date), by=\"days\")\n\n  # Setup data frame to recieve data\n  #totalpagedata <- data.frame()\n\n  # Retrieve Page Posts from Start to End Date\n  page <- getPage(pageid, ftoken, n = posts, since = UnixDate(start.date), until = UnixDate(end.date))\n\n  ## Appending Routine ---\n\n  # Add some date columns\n  page[, 'datetime'] = UnixDate(page$created_time)\n  page[, 'day'] = format(page$datetime, \"%Y-%m-%d\")\n  page[, 'month'] = format(page$datetime, \"%Y-%m\")\n\n  ## Retrieval Routine ---\n\n  period = 'day'\n\n  pull <- getInsights(object_id=pageid, token=ftoken, metric=dailymetrics[1], period=period, parms=paste0('&since=',unix.start.date,'&until=',unix.end.date))\n\n\n\n  # Retrieve data for metrics\n  for (metric in 1:length(metrics)) {\n\n    print(paste('Finding', names(metrics)[metric],'for',pagedata$page[1]))\n\n    if ((metrics)[metric] == 'page_fans' | (metrics)[metric] == 'page_fans_gender_age') {\n      period = 'lifetime'\n      # Lifetime Metric subroutine\n\n    } else {\n      # Daily Metric subroutine\n      period = 'day'\n\n      try(\n        pull <- getInsights(object_id=pageid, token=ftoken, metric=metrics[metric], period=period, parms=paste0('&since=',start,'&until=',end))\n      )\n\n\n      if (floor < tempfloor) {\n\n        tempremainder = length(range[(length(range)-length(temprange)+1):length(range)])%%5\n        tempweeks  = (length(temprange) - tempremainder)/5 - 2\n        weeks = tempweeks\n\n      } else {}\n    } else {\n      period = 'day'\n      weeks <- (nrow(pagedata)/5)-2\n    }\n\n    hold <- matrix(0, nrow=0, ncol=7)\n\n    for (week in 0:weeks) {\n\n      end <- pagedata$date[(week*5)+1]\n      start <- pagedata$date[((week+1)*5)+1]\n\n      print(paste('Finding', names(metrics)[metric],'for',pagedata$page[1],'from',start,'to',end))\n\n      pull <- NULL\n      attempt <- 1\n\n      while(is.null(pull) && attempt <= 10) {\n        attempt <- attempt + 1\n        try(\n          pull <- getInsights(object_id=pageid, token=ftoken, metric=metrics[metric], period=period, parms=paste0('&since=',start,'&until=',end))\n        )\n\n        if (is.null(pull)) {\n          print(\"Empty Pull. Re-attempting.\")\n          print(paste(\"Attempt\", attempt))\n        } else {\n          pull$datetime <- format.facebook.date(pull$end_time)\n          pull$day <- format(pull$datetime, \"%Y-%m-%d\")\n\n          pull$datetime <- as.Date(pull$datetime)\n          #page$month <- as.Date(page$month)\n          pull$day <- as.Date(pull$day)\n\n          if ((seq(from=start, to=(end-1), by = \"days\")[1] == pull$day[1]) & (seq(from=start, to=end, by = \"days\")[5] == pull$day[length(pull$day)]) == TRUE) {\n            print(\"Found Facebook data matching date range. Storing values.\")\n          } else {\n            print(\"Did not find Facebook data matching dataset dates. Re-querying.\")\n            print(paste(\"Attempt\", attempt))\n            pull <- NULL}\n\n          if (attempt > 100) {\n            print('Too many attempts. Skipping.')\n            pull <- NULL\n            break\n          } else {}\n        }\n\n        pulllength <- ncol(pull)\n\n        rpull = pull[rev(rownames(pull)),]\n\n        hold <- rbind(hold,rpull)\n        rawhold <- hold\n      }\n    }\n\n\n\n    rhold = hold[rev(rownames(hold)),]\n    rhold$value = shift(rhold$value, 1)\n    hold = rhold[rev(rownames(rhold)),]\n    hold$value[1] = rawhold$value[1]\n\n    hours <- seq(0,23)\n    names(hours) <- paste(\"Hour\", hours)\n\n    subtypes <- c('link','comment', 'like')\n    names(subtypes) <- c('Shares','Comments', 'Likes')\n\n    demographics <- c(\"F.65+\",\"F.55-64\", \"F.45-54\",\"F.35-44\", \"F.25-34\", \"F.18-24\", \"M.65+\", \"M.55-64\", \"M.45-54\", \"M.35-44\",\"M.25-34\", \"M.18-24\", \"U.65+\", \"U.55-64\", \"U.45-54\", \"U.35-44\", \"U.25-34\", \"U.18-24\")\n    names(demographics)  <- c(\"Females 65+\", \"Females 55-64\", \"Females 45-54\", \"Females 35-44\", \"Females 25-34\", \"Females 18-24\",  \"Males 65+\", \"Males 55-64\", \"Males 45-54\", \"Males 35-44\", \"Males 25-34\", \"Males 18-24\",  \"Unidentified 65+\", \"Unidentified 55-64\", \"Unidentified 45-54\", \"Unidentified 35-44\", \"Unidentified 25-34\", \"Unidentified 18-24\")\n\n    # Posting demographics at the end of the loop as metrics[metric]; fix the tail end of the loop.\n\n    if ((metrics)[metric] == 'page_positive_feedback_by_type') {\n\n      for (type in 1:length(subtypes)) {\n        typehold <- NA\n        typehold <- hold[hold$variable == subtypes[type],]\n\n        pagedata <- cbind(NA,pagedata)\n        pagedata[2:(length(typehold$day)+1),1] <- (typehold$value)\n        colnames(pagedata)[1] = paste0(tolower(names(subtypes[type])))\n\n        metrics <- c(metrics,subtypes[type])\n      }\n\n\n    } else if ((metrics)[metric] == 'page_fans_gender_age') {\n\n      for (demographic in 1:length(demographics)) {\n\n        print(names(demographics[demographic]))\n\n        typehold <- NA\n        typehold <- hold[hold$variable == demographics[demographic],]\n        typehold[typehold$value <= 10,] <- NA\n\n        pagedata <- cbind(NA,pagedata)\n        pagedata[2:(length(typehold$day)+1),1] <- (typehold$value)\n        colnames(pagedata)[1] = paste0(tolower(demographics[demographic]))\n\n        metrics <- c(metrics,demographics[demographic])\n      }\n\n    } else if ((metrics)[metric] == 'page_fans_online') {\n\n      for (hour in 1:length(hours)) {\n\n        typehold <- NA\n        typehold <- hold[hold$variable == hours[hour],]\n\n        pagedata <- cbind(NA,pagedata)\n        pagedata[2:(length(typehold$day)+1),1] <- (typehold$value)\n        colnames(pagedata)[1] = paste(\"hour\",hours[hour])\n\n        metrics <- c(metrics,hours[hour])\n      }\n    } else {\n      pagedata <- cbind(NA,pagedata)\n      pagedata[2:(length(hold$day)+1),1] <- (hold$value)\n      colnames(pagedata)[1] = paste0(tolower(names(metrics[metric])))\n\n    }\n\n    cat(\"\\n\\n\")\n    print(head(pagedata))\n    cat(\"\\n\")\n\n    if (length(metrics) == (length(pagemetrics)  + length(demographics) + length(hours))) {\n      break\n    } else {\n    }\n\n  }\n\n  pagedata.tempstore <- pagedata\n\n  #Page Metrics to remove because they have subtypes\n  metrics <- metrics[-c(which(metrics == \"page_positive_feedback_by_type\"),which(metrics == \"page_fans_gender_age\"),which(metrics == \"page_fans_online\"))]\n\n  # Page Metrics to manually create\n  metrics <- c(metrics,\"organic reach\")\n  names(metrics)[length(metrics)] <- c(\"Organic Reach\")\n\n  pagedata <- cbind((as.numeric(pagedata$`total reach`) - as.numeric(pagedata$`paid reach`)),pagedata)\n  colnames(pagedata)[1] = \"organic reach\"\n\n  # Final dataset formatting\n  pagedatastore <- pagedata\n  #pagedata <- pagedatastore\n  pagedata2 <- pagedata\n\n  # reorder and null NA's for excel\n  pagedata2 <- pagedata2[,c((ncol(pagedata)-2), (ncol(pagedata)-1),(ncol(pagedata)),(1:(ncol(pagedata)-3)))]\n  pagedata2 <- pagedata2[2:nrow(pagedata2),]\n  #pagedata2[is.na(pagedata2)] <- \"\"\n  #pagedata2[pagedata2 == 0] <- \"\"\n\n  # store final dataset\n  pagedata <- pagedata2\n\n}\n\n\n\nfor (brand in 1:length(ftokens)) {\n\nftoken = ftoken[brand] # Use the brands ftoken\n\n  # Processing --------------------------------------------------------------\n  # Process data to clean dataset and augment it with more data than default fields.\n  # Check full package documentation for reference: http://cran.r-project.org/web/packages/Rfacebook/Rfacebook.pdf\n\n\n## Cleaning =================================\n\n# Page and Post Datasets\n# Split dataset into two for pages and post data\n# Create initial null sets\npagedata <- 0\npostdata <- 0\n\n## Appending =================================\n\n### Page Metrics #############################\n# Loop through all dates for the specified metric(s), and append the page dataset with metric values\n# Some are automated, others are manual; after the script. Re-run from pull loop if there is an error; should auto-try until values are found.\n\n# Pa\n\n# Start Data Acquisition Loop\nfor (metric in 1:length(metrics)) {\n\n  print(paste('Finding', names(metrics)[metric],'for',pagedata$page[1]))\n\n  if ((metrics)[metric] == 'page_fans' | (metrics)[metric] == 'page_fans_gender_age') {\n    period = 'lifetime'\n  } else if ((metrics)[metric] == 'page_positive_feedback_by_type'| (metrics)[metric] == 'page_positive_feedback_by_type' ) {\n    period = 'day'\n\n    tempfloor = \"2014-02-01\"\n    temprange = seq(as.Date(tempfloor), as.Date(roof), by=\"days\")\n\n    if (floor < tempfloor) {\n\n    tempremainder = length(range[(length(range)-length(temprange)+1):length(range)])%%5\n    tempweeks  = (length(temprange) - tempremainder)/5 - 2\n    weeks = tempweeks\n\n    } else {}\n    } else {\n    period = 'day'\n    weeks <- (nrow(pagedata)/5)-2\n  }\n\n  hold <- matrix(0, nrow=0, ncol=7)\n\n  for (week in 0:weeks) {\n\n    end <- pagedata$date[(week*5)+1]\n    start <- pagedata$date[((week+1)*5)+1]\n\n    print(paste('Finding', names(metrics)[metric],'for',pagedata$page[1],'from',start,'to',end))\n\n    pull <- NULL\n    attempt <- 1\n\n    while(is.null(pull) && attempt <= 10) {\n      attempt <- attempt + 1\n      try(\n        pull <- getInsights(object_id=pageid, token=ftoken, metric=metrics[metric], period=period, parms=paste0('&since=',start,'&until=',end))\n      )\n\n      if (is.null(pull)) {\n        print(\"Empty Pull. Re-attempting.\")\n        print(paste(\"Attempt\", attempt))\n      } else {\n        pull$datetime <- format.facebook.date(pull$end_time)\n        pull$day <- format(pull$datetime, \"%Y-%m-%d\")\n\n        pull$datetime <- as.Date(pull$datetime)\n        #page$month <- as.Date(page$month)\n        pull$day <- as.Date(pull$day)\n\n        if ((seq(from=start, to=(end-1), by = \"days\")[1] == pull$day[1]) & (seq(from=start, to=end, by = \"days\")[5] == pull$day[length(pull$day)]) == TRUE) {\n          print(\"Found Facebook data matching date range. Storing values.\")\n        } else {\n          print(\"Did not find Facebook data matching dataset dates. Re-querying.\")\n          print(paste(\"Attempt\", attempt))\n          pull <- NULL}\n\n        if (attempt > 100) {\n          print('Too many attempts. Skipping.')\n          pull <- NULL\n          break\n        } else {}\n      }\n\n      pulllength <- ncol(pull)\n\n      rpull = pull[rev(rownames(pull)),]\n\n      hold <- rbind(hold,rpull)\n      rawhold <- hold\n    }\n  }\n\n\n\n  rhold = hold[rev(rownames(hold)),]\n  rhold$value = shift(rhold$value, 1)\n  hold = rhold[rev(rownames(rhold)),]\n  hold$value[1] = rawhold$value[1]\n\nhours <- seq(0,23)\nnames(hours) <- paste(\"Hour\", hours)\n\nsubtypes <- c('link','comment', 'like')\nnames(subtypes) <- c('Shares','Comments', 'Likes')\n\ndemographics <- c(\"F.65+\",\"F.55-64\", \"F.45-54\",\"F.35-44\", \"F.25-34\", \"F.18-24\", \"M.65+\", \"M.55-64\", \"M.45-54\", \"M.35-44\",\"M.25-34\", \"M.18-24\", \"U.65+\", \"U.55-64\", \"U.45-54\", \"U.35-44\", \"U.25-34\", \"U.18-24\")\nnames(demographics)  <- c(\"Females 65+\", \"Females 55-64\", \"Females 45-54\", \"Females 35-44\", \"Females 25-34\", \"Females 18-24\",  \"Males 65+\", \"Males 55-64\", \"Males 45-54\", \"Males 35-44\", \"Males 25-34\", \"Males 18-24\",  \"Unidentified 65+\", \"Unidentified 55-64\", \"Unidentified 45-54\", \"Unidentified 35-44\", \"Unidentified 25-34\", \"Unidentified 18-24\")\n\n# Posting demographics at the end of the loop as metrics[metric]; fix the tail end of the loop.\n\n  if ((metrics)[metric] == 'page_positive_feedback_by_type') {\n\n    for (type in 1:length(subtypes)) {\n      typehold <- NA\n      typehold <- hold[hold$variable == subtypes[type],]\n\n      pagedata <- cbind(NA,pagedata)\n      pagedata[2:(length(typehold$day)+1),1] <- (typehold$value)\n      colnames(pagedata)[1] = paste0(tolower(names(subtypes[type])))\n\n      metrics <- c(metrics,subtypes[type])\n    }\n\n\n  } else if ((metrics)[metric] == 'page_fans_gender_age') {\n\n    for (demographic in 1:length(demographics)) {\n\n      print(names(demographics[demographic]))\n\n      typehold <- NA\n      typehold <- hold[hold$variable == demographics[demographic],]\n      typehold[typehold$value <= 10,] <- NA\n\n      pagedata <- cbind(NA,pagedata)\n      pagedata[2:(length(typehold$day)+1),1] <- (typehold$value)\n      colnames(pagedata)[1] = paste0(tolower(demographics[demographic]))\n\n      metrics <- c(metrics,demographics[demographic])\n    }\n\n  } else if ((metrics)[metric] == 'page_fans_online') {\n\n    for (hour in 1:length(hours)) {\n\n      typehold <- NA\n      typehold <- hold[hold$variable == hours[hour],]\n\n      pagedata <- cbind(NA,pagedata)\n      pagedata[2:(length(typehold$day)+1),1] <- (typehold$value)\n      colnames(pagedata)[1] = paste(\"hour\",hours[hour])\n\n      metrics <- c(metrics,hours[hour])\n    }\n  } else {\n    pagedata <- cbind(NA,pagedata)\n    pagedata[2:(length(hold$day)+1),1] <- (hold$value)\n    colnames(pagedata)[1] = paste0(tolower(names(metrics[metric])))\n\n  }\n\n  cat(\"\\n\\n\")\n  print(head(pagedata))\n  cat(\"\\n\")\n\n  if (length(metrics) == (length(pagemetrics)  + length(demographics) + length(hours))) {\n    break\n  } else {\n  }\n\n}\n\npagedata.tempstore <- pagedata\n\n#Page Metrics to remove because they have subtypes\nmetrics <- metrics[-c(which(metrics == \"page_positive_feedback_by_type\"),which(metrics == \"page_fans_gender_age\"),which(metrics == \"page_fans_online\"))]\n\n# Page Metrics to manually create\nmetrics <- c(metrics,\"organic reach\")\nnames(metrics)[length(metrics)] <- c(\"Organic Reach\")\n\npagedata <- cbind((as.numeric(pagedata$`total reach`) - as.numeric(pagedata$`paid reach`)),pagedata)\ncolnames(pagedata)[1] = \"organic reach\"\n\n# Final dataset formatting\npagedatastore <- pagedata\n#pagedata <- pagedatastore\npagedata2 <- pagedata\n\n# reorder and null NA's for excel\npagedata2 <- pagedata2[,c((ncol(pagedata)-2), (ncol(pagedata)-1),(ncol(pagedata)),(1:(ncol(pagedata)-3)))]\npagedata2 <- pagedata2[2:nrow(pagedata2),]\n#pagedata2[is.na(pagedata2)] <- \"\"\n#pagedata2[pagedata2 == 0] <- \"\"\n\n# store final dataset\npagedata <- pagedata2\n\n### Post Metrics #############################\n# Loop through all posts for the specified metric(s), and append the post dataset with metric values\n# Most are automated, and will continue to retry through errors until a value is found.\n# Manual modifications are run after initial data acquisition.\n\npostmetrics = c(\"post_impressions_unique\",\"post_impressions_paid_unique\",\"post_video_views_organic\",\"post_video_views_paid\",\"post_video_complete_views_organic\",\"post_video_complete_views_paid\",\"post_engaged_users\",\"post_consumptions_by_type\")\nnames(postmetrics) = c(\"Total Reach\", \"Paid Reach\",\"Organic Video Views\", \"Paid Video Views\", \"Organic Complete Video Views\", \"Paid Complete Video Views\",\"Engaged Users\", \"Post Consumptions\")\n\n# Populate sets with values from pull\n\nif ((is.null(page$datetime[1]) & is.null(page$month[1]) & is.null(page$day[1])) == TRUE) {\n  page$datetime <- format.facebook.date(page$created_time)\n  page$month <- format(page$datetime, \"%Y-%m\")\n  page$day <- format(page$datetime, \"%Y-%m-%d\")\n\n  page$datetime <- as.Date(page$datetime)\n  #page$month <- as.Date(page$month)\n  page$day <- as.Date(page$day)\n} else {\n  print(\"Date fields already exist for Post Data.\")\n}\n\npostdata <- 0\npostdata <- page[page$day > floor,]\npostdata <- postdata[postdata$day < roof,]\n\n#write.xlsx(postdata, paste0(paste(me$name,floor,\"to\",roof,sep=\" \"),\".xlsx\"), row.names=FALSE)\n\n\n# Name column for usability\ncolnames(postdata) = c(\"pageid\", \"page\", \"message\", \"created\", \"type\", \"link\", \"postid\", \"likes\", \"comments\", \"shares\", \"datetime\", \"month\",\"day\")\n\nrows <- nrow(postdata)\nlpostmetrics <- postmetrics\n\n#testlength <- 2\n#length(postmetrics) instead of testlength; swapped out for hotfixes\n\n\nfor (pmetric in 1:length(postmetrics)) {\n  print(paste('Finding', names(postmetrics)[pmetric],'for',postdata$from_name[1]))\n\n  if ((substr((postmetrics)[pmetric], 1, 17) == ('post_consumptions'))) {\n    phold <- data.frame(0,0,0,0,0,0,0, stringsAsFactors=FALSE)\n    names(phold) <- c(\"id\",\"name\",\"period\",\"title\",\"description\",\"value\",\"variable\")\n  } else {\n    phold <- data.frame(0,0,0,0,0,0, stringsAsFactors=FALSE)\n    names(phold) <- c(\"id\",\"name\",\"period\",\"title\",\"description\",\"value\")\n  }\n\n\n  for (post in 1:nrow(postdata)) {\n\n    period <- \"lifetime\"\n\n\n    print(paste('Finding', names(postmetrics)[pmetric],'for',postdata$page[1], postdata$type[post],'post:',paste0(substr(postdata$message[post], 1, 80),\"...\")))\n\n      if ((substr((postmetrics)[pmetric], 1, 10) == ('post_video')) & (postdata$type[post] != 'video')) {\n      print('Not a Facebook Video.')\n      phold <- rbind(phold, NA)\n      next()\n      } else if ((substr((postmetrics)[pmetric], 1, 10) == ('post_video')) & (postdata$type[post] == 'video') & (substr(postdata$link[post], 12, 18) != 'youtube') & (substr(postdata$link[post], 8, 15) != 'youtu.be')) {\n      } else {\n      }\n\n\n    postpull <- NULL\n    attempt <- 1\n\n    while( is.null(postpull) && attempt <= 50) {\n      attempt <- attempt + 1\n      try(\n        postpull <- getInsights(object_id=postdata$postid[post], token=ftoken, metric=postmetrics[pmetric], period=period)\n        #,silent=TRUE\n      )\n      if (attempt > 10) {\n        print('Too many attempts. Skipping.')\n        postpull <- NULL\n        break\n      } else {\n        print('Retrying.')\n      }\n    }\n\n    colnames(phold) <- names(postpull)\n    phold <- rbind(phold, postpull)\n  }\n  pholdstore <- phold\n\n  psubtypes <- c('other clicks','photo view', 'link clicks', 'video play')\n  names(psubtypes) <- c('Other Clicks','Photo Views', 'Link Clicks', 'Video Plays')\n\n  phold <- phold[-1,]\n\n  if ((postmetrics)[pmetric] == 'post_consumptions_by_type') {\n\n    postmetrics <- postmetrics[-pmetric]\n    pmetric <- pmetric + 1\n\n    for (ptype in (1:length(psubtypes))) {\n      ptyphehold <- NA\n      ptypehold <- phold[phold$variable == psubtypes[ptype],]\n\n      postdata <- cbind(NA,postdata)\n      postdata[match(substr(ptypehold$id, 1, 22), substr(postdata$postid, 1, 22)),1] <- ptypehold$value\n\n      colnames(postdata)[1] = paste0(tolower(names(psubtypes[ptype])))\n      postmetrics <- c(postmetrics,psubtypes[ptype])\n    }\n\n\n  } else {\n    postdata <- cbind(NA,postdata)\n    postdata[1:length(phold$value),1] <- phold$value\n    colnames(postdata)[1] = paste0(tolower(names(postmetrics[pmetric])))\n  }\n\n\n  cat(\"\\n\\n\")\n  print(head(postdata))\n  cat(\"\\n\")\n}\n\npostdatastore <- postdata\n\n# Post Metrics to manually create\npostmetrics <- c(postmetrics,\"organic reach\")\nnames(postmetrics)[length(postmetrics)] <- c(\"Organic Reach\")\n\npostdata <- cbind((as.numeric(postdata$`total reach`) - as.numeric(postdata$`paid reach`)),postdata)\ncolnames(postdata)[1] = \"organic reach\"\n\n# Final dataset formatting\n#postdatastore <- postdata\n#postdata <- postdatastore\n\n#head(postdatastore[,c((ncol(postdata)-12),(ncol(postdata)-11),(ncol(postdata)-9),(ncol(postdata)-2), (ncol(postdata)-1),ncol(postdata),(ncol(postdata)-6),(ncol(postdata)-7),(ncol(postdata)-8),(ncol(postdata)-10),(ncol(postdata)-5),(ncol(postdata)-4),(ncol(postdata)-3),(1:(ncol(postdata)-13)))])\n\n# reorder and null NA's for Excel\npostdata2 <- postdata\npostdata2 <- postdata2[,c((ncol(postdata)-12),(ncol(postdata)-11),(ncol(postdata)-9),(ncol(postdata)-2), (ncol(postdata)-1),ncol(postdata),(ncol(postdata)-6),(ncol(postdata)-7),(ncol(postdata)-8),(ncol(postdata)-10),(ncol(postdata)-5),(ncol(postdata)-4),(ncol(postdata)-3),(1:(ncol(postdata)-13)))]\npostdata2[is.na(postdata2)] <- \"\"\npostdata2[postdata2 == 0] <- \"\"\n\n# store final dataset\npostdata <- as.data.frame(postdata2)\n\n# Outputs -----------------------------------------------------------------\n\npagedata[,-c(1:3)] <- sapply(pagedata[,-c(1:3)], as.numeric)\npostdata[,-c(1:10)] <- sapply(postdata[,-c(1:10)], as.numeric)\n\ndatafolder <- \"Data\"\n\ndir.create(file.path(getwd(), datafolder), showWarnings = FALSE)\n\n# Rename columns for Excel readability\n#names(pagedata) = c(\"Page ID\", \"Page Name\", \"Date\", rev(names(metrics)))\n# output Page dataset as final csv\n#write.csv(pagedata, paste0(paste(page$from_name[1],\"Page Data\",Sys.Date(), sep=\" \"),\".csv\"),row.names=FALSE, fileEncoding='iso-8859-1')\nwrite.xlsx(pagedata, paste0(getwd(),\"/\",datafolder,\"/\",paste(page$from_name[1],\"Page Data\",Sys.Date(), sep=\" \"),\".xlsx\"), row.names=FALSE, showNA=FALSE)\n\n# Rename columns for Excel readability\n#names(postdata) = c(\"Page ID\", \"Page Name\", \"Created\",  \"Datetime\", \"Month\", \"Day\", \"Post ID\", \"Link\", \"Type\", \"Message\", \"Likes\", \"Comments\", \"Shares\", rev(names(postmetrics)))\n# output Post dataset as final Excel\n#write.csv(postdata, paste0(paste(page$from_name[1],\"Post Data\",Sys.Date(), sep=\" \"),\".csv\"),row.names=FALSE)\nwrite.xlsx(postdata, paste0(getwd(),\"/\",datafolder,\"/\",paste(page$from_name[1],\"Post Data\",Sys.Date(), sep=\" \"),\".xlsx\"), row.names=FALSE, showNA=FALSE)\n\n# Raw Data\n# output dataset as raw csv\n#write.csv(page, paste0(paste(me$name,\"Raw Data\",Sys.Date(), sep=\" \"),\".csv\"),row.names=FALSE)\n\ntotalpagedata <- rbind(totalpagedata, pagedata)\ntotalpostdata <- rbind(totalpostdata, postdata)\n\n}\n\ndataname = 'Milk'\n\nwrite.xlsx(totalpagedata, paste0(getwd(),\"/\",datafolder,\"/\",paste(dataname, \"Page Data\",Sys.Date(), sep=\" \"),\".xlsx\"), row.names=FALSE, showNA=FALSE)\n# Rename columns for Excel readability\n#names(postdata) = c(\"Page ID\", \"Page Name\", \"Created\",  \"Datetime\", \"Month\", \"Day\", \"Post ID\", \"Link\", \"Type\", \"Message\", \"Likes\", \"Comments\", \"Shares\", rev(names(postmetrics)))\n\n# output Post dataset as final Excel\n#write.csv(postdata, paste0(paste(page$from_name[1],\"Post Data\",Sys.Date(), sep=\" \"),\".csv\"),row.names=FALSE)\nwrite.xlsx(totalpostdata, paste0(getwd(),\"/\",datafolder,\"/\",paste(dataname,\"Post Data\",Sys.Date(), sep=\" \"),\".xlsx\"), row.names=FALSE, showNA=FALSE)\n\n# Images\n#imagefolder <- paste0(\"Images\",\"/\",paste(page$from_name[1],sep=\" \"))#,floor,\"to\", roof, sep=\" \"))\n\n#for (picture in (1:nrow(postdata))) {\n#  dir.create(file.path(getwd(), imagefolder), showWarnings = FALSE)\n#\n#  imageURL <- fromJSON(getURL(paste('https://graph.facebook.com/v2.4/',postdata$`Post ID`[picture],'?fields=full_picture&access_token=',ftoken,sep=\"\")))$full_picture\n#  filename <- paste0(getwd(), \"/\", imagefolder, \"/\", postdata$`Post ID`[picture], \".png\")\n#\n#  try(GET(imageURL, write_disk(filename, overwrite=TRUE)))\n\n\n# Edit the core program and change feedback loop.\n\n#\n#}\n\n\n## People Metrics\ntry(\n  test <- getInsights(object_id=pageid, token=ftoken, metric=\"page_fans_by_like_source\", parms=paste0('&since=',floor,'&until=',roof))\n)\n\nfanmetrics <- c('page_fans_gender_age'\n,'page_fans_country'\n,'page_fans_city'\n,'page_fans')\n\ntest <- getInsights(object_id=pageid, token=ftoken, metric=fanmetrics, period='lifetime', parms=paste0('&since=',floor,'&until=',roof))\n\nfor (i in seq_along(test)) {\n  filename = paste(\"Baron Samedi\", names(test)[i], \".csv\")\n  write.csv(test[[i]], filename)\n}\n",
    "created" : 1463425992960.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2402606727",
    "id" : "F7F2162",
    "lastKnownWriteTime" : 1490382895,
    "last_content_update" : 1490382946978,
    "path" : "~/Documents/Work/Internal/Scripts/FacebookQueryv2.R",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}